{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful commands in bash that I never manage to remember\n",
    "# Strings\n",
    "## Remove extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angleur_SartTilman_2017_06_28_07_23_49_Running_noextensions.gpx\n"
     ]
    }
   ],
   "source": [
    "a=\"Angleur_SartTilman_2017_06_28_07_23_49_Running_noextensions.gpx\"\n",
    "echo $a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angleur_SartTilman_2017_06_28_07_23_49_Running_noextensions\n"
     ]
    }
   ],
   "source": [
    "y=${a%.*}\n",
    "echo $y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goodnight\n"
     ]
    }
   ],
   "source": [
    "a='good'\n",
    "b='night'\n",
    "a+=$b\n",
    "echo $a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rename 's/GCAN/GranCanaria/g' *JPG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File processing\n",
    "## Create a temporaty file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmp.jIPszU0uKX\n"
     ]
    }
   ],
   "source": [
    "mktemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove lines containing pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the 1st line\n",
      "And this is a 2nd line\n",
      " \n",
      "This is the 1st line\n"
     ]
    }
   ],
   "source": [
    "mytmpfile=$(mktemp)\n",
    "echo \"This is the 1st line\" > ${mytmpfile}\n",
    "echo \"And this is a 2nd line\" >> ${mytmpfile}\n",
    "cat ${mytmpfile}\n",
    "echo \" \"\n",
    "sed -i '/2nd/d' ${mytmpfile}\n",
    "cat ${mytmpfile}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# List files\n",
    "## Find files containing a given string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find: ‘/home/ctroupin/.cache/dconf’: Permission denied\n"
     ]
    }
   ],
   "source": [
    "find /home/ctroupin/ -name '*' -type f -exec grep -i 'product_id,old_product_id'  {} +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find: ‘/home/ctroupin/.cache/dconf’: Permission denied\n",
      "find: ‘/home/ctroupin/.dbus’: Permission denied\n",
      "/home/ctroupin/Papers/BibTexFiles/PubliUpwelling.tex:%\\newblock {M}ean structure of the inshore countercurrent and {C}alifornia\n",
      "/home/ctroupin/Papers/BibTexFiles/PubliUpwelling.tex:%\\newblock Fronts, jets, and counter-flows in the {W}estern {I}berian upwelling\n",
      "/home/ctroupin/Papers/BibTexFiles/PubliUpwelling.tex:%\\newblock A separated jet and coastal counterflow during upwelling relaxation\n",
      "/home/ctroupin/R/x86_64-pc-linux-gnu-library/3.4/rmarkdown/rmd/latex/default.tex:\\setcounter{secnumdepth}{5}\n",
      "/home/ctroupin/R/x86_64-pc-linux-gnu-library/3.4/rmarkdown/rmd/latex/default.tex:\\setcounter{secnumdepth}{0}\n",
      "/home/ctroupin/R/x86_64-pc-linux-gnu-library/3.4/rmarkdown/rmd/latex/default.tex:\\setcounter{tocdepth}{$toc-depth$}\n",
      "/home/ctroupin/R/x86_64-pc-linux-gnu-library/3.4/rmarkdown/rmd/latex/default-1.15.2.tex:\\setcounter{secnumdepth}{5}\n",
      "/home/ctroupin/R/x86_64-pc-linux-gnu-library/3.4/rmarkdown/rmd/latex/default-1.15.2.tex:\\setcounter{secnumdepth}{0}\n",
      "/home/ctroupin/R/x86_64-pc-linux-gnu-library/3.4/rmarkdown/rmd/latex/default-1.15.2.tex:\\setcounter{tocdepth}{$toc-depth$}\n",
      "/home/ctroupin/R/x86_64-pc-linux-gnu-library/3.4/rmarkdown/rmd/latex/default-1.14.tex:\\setcounter{secnumdepth}{5}\n",
      "/home/ctroupin/R/x86_64-pc-linux-gnu-library/3.4/rmarkdown/rmd/latex/default-1.14.tex:\\setcounter{secnumdepth}{0}\n",
      "/home/ctroupin/R/x86_64-pc-linux-gnu-library/3.4/rmarkdown/rmd/latex/default-1.14.tex:\\setcounter{tocdepth}{$toc-depth$}\n",
      "/home/ctroupin/R/x86_64-pc-linux-gnu-library/3.4/rmarkdown/rmd/latex/default-1.17.0.2.tex:\\setcounter{secnumdepth}{5}\n",
      "/home/ctroupin/R/x86_64-pc-linux-gnu-library/3.4/rmarkdown/rmd/latex/default-1.17.0.2.tex:\\setcounter{secnumdepth}{0}\n",
      "/home/ctroupin/R/x86_64-pc-linux-gnu-library/3.4/rmarkdown/rmd/latex/default-1.17.0.2.tex:\\setcounter{tocdepth}{$toc-depth$}\n",
      "/home/ctroupin/Documents/DOX/Publi/Review/ReviewYeray.tex:\\newcounter{enumTemp}\n",
      "/home/ctroupin/Documents/DOX/Publi/Review/ReviewYeray.tex: \\setcounter{enumTemp}{\\theenumi}\n",
      "/home/ctroupin/Documents/DOX/Publi/Review/ReviewYeray.tex:\\setcounter{enumi}{\\theenumTemp}\n",
      "/home/ctroupin/Documents/DOX/Publi/Review/ReviewYeray.tex:\\setcounter{enumTemp}{\\theenumi}\n",
      "/home/ctroupin/Documents/DOX/Publi/Review/ReviewYeray.tex:\\setcounter{enumi}{\\theenumTemp}\n",
      "/home/ctroupin/Documents/DOX/Publi/Review/ReviewYeray.tex:\\setcounter{enumTemp}{\\theenumi}\n",
      "/home/ctroupin/Documents/DOX/Publi/Review/ReviewYeray.tex:\\setcounter{enumi}{\\theenumTemp}\n",
      "/home/ctroupin/Documents/DOX/Publi/Review/ReviewYeray.tex: \\setcounter{enumTemp}{\\theenumi}\n",
      "/home/ctroupin/Documents/DOX/Publi/Review/ReviewYeray.tex:\\setcounter{enumi}{\\theenumTemp}\n",
      "/home/ctroupin/Documents/Administration et bourses/Fria2/FRIA2_slides/figures/figures.tex:\\setcounter{figure}{4}.\n",
      "/home/ctroupin/Documents/Administration et bourses/Fria2/FRIA2_slides/figures/figures.tex:\\setcounter{figure}{6}.\n",
      "/home/ctroupin/Documents/Administration et bourses/Fria2/FRIA2_slides/figures/figures.tex:\\setcounter{figure}{7}.\n",
      "/home/ctroupin/dox/Publi/Review/ReviewYeray.tex:\\newcounter{enumTemp}\n",
      "/home/ctroupin/dox/Publi/Review/ReviewYeray.tex: \\setcounter{enumTemp}{\\theenumi}\n",
      "/home/ctroupin/dox/Publi/Review/ReviewYeray.tex:\\setcounter{enumi}{\\theenumTemp}\n",
      "/home/ctroupin/dox/Publi/Review/ReviewYeray.tex:\\setcounter{enumTemp}{\\theenumi}\n",
      "/home/ctroupin/dox/Publi/Review/ReviewYeray.tex:\\setcounter{enumi}{\\theenumTemp}\n",
      "/home/ctroupin/dox/Publi/Review/ReviewYeray.tex:\\setcounter{enumTemp}{\\theenumi}\n",
      "/home/ctroupin/dox/Publi/Review/ReviewYeray.tex:\\setcounter{enumi}{\\theenumTemp}\n",
      "/home/ctroupin/dox/Publi/Review/ReviewYeray.tex: \\setcounter{enumTemp}{\\theenumi}\n",
      "/home/ctroupin/dox/Publi/Review/ReviewYeray.tex:\\setcounter{enumi}{\\theenumTemp}\n",
      "/home/ctroupin/Projects/ContextureWeb/contexture-Archi.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% This is the counter used by @enumerate, which is really @itemize\n",
      "/home/ctroupin/Projects/ContextureWeb/contexture-Archi.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% we encounter the problem it was intended to solve again.\n",
      "/home/ctroupin/Projects/ContextureWeb/contexture-Archi.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:      \\global\\colcount=0 % Reset the column counter.\n",
      "/home/ctroupin/Projects/ContextureWeb/contexture-Archi.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% This counter is funny since it counts through charcodes of letters A, B, ...\n",
      "/home/ctroupin/Projects/ContextureWeb/contexture-Archi.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% @chapter, @appendix, @unnumbered.  Increment top-level counter, reset\n",
      "/home/ctroupin/Projects/ContextureWeb/contexture-Archi.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% all lower-level sectioning counters to zero.\n",
      "/home/ctroupin/Projects/ContextureWeb/contexture-Archi.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% If we encounter &foo, then turn on ()-hacking afterwards\n",
      "/home/ctroupin/Projects/ContextureWeb/contexture-Archi.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% We keep a separate counter for each FLOATTYPE, which we reset at each\n",
      "/home/ctroupin/Projects/ContextureWeb/contexture-Archi.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% The parameter is the control sequence identifying the counter we are\n",
      "/home/ctroupin/Projects/ContextureWeb/V1/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% This is the counter used by @enumerate, which is really @itemize\n",
      "/home/ctroupin/Projects/ContextureWeb/V1/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% we encounter the problem it was intended to solve again.\n",
      "/home/ctroupin/Projects/ContextureWeb/V1/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:      \\global\\colcount=0 % Reset the column counter.\n",
      "/home/ctroupin/Projects/ContextureWeb/V1/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% This counter is funny since it counts through charcodes of letters A, B, ...\n",
      "/home/ctroupin/Projects/ContextureWeb/V1/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% @chapter, @appendix, @unnumbered.  Increment top-level counter, reset\n",
      "/home/ctroupin/Projects/ContextureWeb/V1/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% all lower-level sectioning counters to zero.\n",
      "/home/ctroupin/Projects/ContextureWeb/V1/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% If we encounter &foo, then turn on ()-hacking afterwards\n",
      "/home/ctroupin/Projects/ContextureWeb/V1/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% We keep a separate counter for each FLOATTYPE, which we reset at each\n",
      "/home/ctroupin/Projects/ContextureWeb/V1/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% The parameter is the control sequence identifying the counter we are\n",
      "/home/ctroupin/Projects/ctroupin.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% This is the counter used by @enumerate, which is really @itemize\n",
      "/home/ctroupin/Projects/ctroupin.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% we encounter the problem it was intended to solve again.\n",
      "/home/ctroupin/Projects/ctroupin.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:      \\global\\colcount=0 % Reset the column counter.\n",
      "/home/ctroupin/Projects/ctroupin.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% This counter is funny since it counts through charcodes of letters A, B, ...\n",
      "/home/ctroupin/Projects/ctroupin.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% @chapter, @appendix, @unnumbered.  Increment top-level counter, reset\n",
      "/home/ctroupin/Projects/ctroupin.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% all lower-level sectioning counters to zero.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ctroupin/Projects/ctroupin.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% If we encounter &foo, then turn on ()-hacking afterwards\n",
      "/home/ctroupin/Projects/ctroupin.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% We keep a separate counter for each FLOATTYPE, which we reset at each\n",
      "/home/ctroupin/Projects/ctroupin.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% The parameter is the control sequence identifying the counter we are\n",
      "/home/ctroupin/Projects/SeaDataCloud/DivaUserGuide/tags/DivaUserGuide_March2013/DivaUserGuide_March2013.tex:\\setcounter{tocdepth}{1}\n",
      "/home/ctroupin/Projects/SeaDataCloud/DivaUserGuide/tags/DivaUserGuide_March2013/16-DivaProblems.tex:\\diva uses a memory allocation for the largest problem encountered. This \n",
      "/home/ctroupin/Projects/SeaDataCloud/DivaUserGuide/tags/DivaUserGuide_March2013/16-DivaProblems.tex:The following problems should not appear any more in the latest version of \\diva. Should you encounter them, please let use know.\n",
      "/home/ctroupin/Projects/SeaDataCloud/DivaUserGuide/DivaUserGuide2013.tex:\\setcounter{tocdepth}{1}\n",
      "/home/ctroupin/Projects/SeaDataCloud/DivaUserGuide/Emodnetspecials.tex:\\setcounter{tocdepth}{1}\n",
      "/home/ctroupin/Projects/SeaDataCloud/DivaUserGuide/testUserGuide.tex:\\setcounter{tocdepth}{1}\n",
      "/home/ctroupin/Projects/SeaDataCloud/DivaUserGuide/DivaUserGuide2012.tex:\\setcounter{tocdepth}{1}\n",
      "/home/ctroupin/Projects/SeaDataCloud/DivaUserGuide/16-DivaProblems.tex:\\diva uses a memory allocation for the largest problem encountered. This \n",
      "/home/ctroupin/Projects/SeaDataCloud/DivaUserGuide/16-DivaProblems.tex:The following problems should not appear any more in the latest version of \\diva. Should you encounter them, please contact us.\n",
      "/home/ctroupin/Projects/SeaDataCloud/DivaUserGuide/DivaUserGuide.tex:\\setcounter{tocdepth}{1}\n",
      "/home/ctroupin/IMEDEA/AltimetryReport/AltimetryHeader.tex:\\setcounter{tocdepth}{3}\n",
      "/home/ctroupin/IMEDEA/AltimetryReport/AltimetryHeader.tex:\\setcounter{tocdepth}{2}\n",
      "/home/ctroupin/Software/netcdf-fortran-4.4.4/docs/texinfo.tex:% This is the counter used by @enumerate, which is really @itemize\n",
      "/home/ctroupin/Software/netcdf-fortran-4.4.4/docs/texinfo.tex:% we again encounter the problem the 1sp was intended to solve.\n",
      "/home/ctroupin/Software/netcdf-fortran-4.4.4/docs/texinfo.tex:      \\global\\colcount=0 % Reset the column counter.\n",
      "/home/ctroupin/Software/netcdf-fortran-4.4.4/docs/texinfo.tex:% This counter is funny since it counts through charcodes of letters A, B, ...\n",
      "/home/ctroupin/Software/netcdf-fortran-4.4.4/docs/texinfo.tex:% @chapter, @appendix, @unnumbered.  Increment top-level counter, reset\n",
      "/home/ctroupin/Software/netcdf-fortran-4.4.4/docs/texinfo.tex:% all lower-level sectioning counters to zero.\n",
      "/home/ctroupin/Software/netcdf-fortran-4.4.4/docs/texinfo.tex:% If we encounter &foo, then turn on ()-hacking afterwards\n",
      "/home/ctroupin/Software/netcdf-fortran-4.4.4/docs/texinfo.tex:% We keep a separate counter for each FLOATTYPE, which we reset at each\n",
      "/home/ctroupin/Software/netcdf-fortran-4.4.4/docs/texinfo.tex:% The parameter is the control sequence identifying the counter we are\n",
      "/home/ctroupin/Software/Latex/packages/academicons/academicons.tex:\\newtotcounter{IconsCounter}\n",
      "/home/ctroupin/Software/Latex/packages/academicons/academicons.tex:\\setcounter{IconsCounter}{0}\n",
      "/home/ctroupin/Software/Latex/packages/academicons/academicons.tex:The \\textsf{\\jobname} package provides specific \\hologo{(La)TeX} bindings with the free \\emph{Academicons} font, allowing to access \\total{IconsCounter} high quality icons of online academic profiles.\n",
      "/home/ctroupin/Software/Latex/packages/academicons/academicons.tex:The \\textsf{\\jobname} package provides access in \\hologo{(La)TeX} to \\total{IconsCounter} high quality icons of online academic profiles included in the free \\emph{Academicons} font. This package requires the \\textsf{fontspec} package and either the \\hologo{Xe}\\hologo{(La)TeX} or Lua\\hologo{(La)TeX} engine to load the \\emph{Academicons} font from the system, which requires installing the bundled \\texttt{academicons.ttf} font file. As new releases come out, it is recommended to install the bundled font version as there may be differences between the package and previous font versions or newest font versions not yet contemplated in the package.\n",
      "/home/ctroupin/Software/Latex/packages/academicons/academicons.tex:\\stepcounter{IconsCounter}%\n",
      "/home/ctroupin/Software/Latex/packages/academicons/academicons.tex:\\stepcounter{IconsCounter}%\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/scratch/SuiteSparse-4.4.5/LDL/Doc/ldl_userguide.tex:If no zero on the diagonal of {\\tt D} is encountered, {\\tt fl} is the\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/scratch/SuiteSparse-4.4.5/LDL/Doc/ldl_userguide.tex:zero entry encountered.  Let {\\tt d=-fl}.  The function returns the\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/scratch/SuiteSparse-4.4.5/CHOLMOD/Doc/UserGuide.tex:    \\item {\\tt cholmod\\_error}: called when CHOLMOD encounters and error.\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/scratch/SuiteSparse-4.4.5/CHOLMOD/Doc/UserGuide.tex:This routine is called when CHOLMOD encounters an error.\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/scratch/SuiteSparse-4.4.5/CHOLMOD/Doc/UserGuide.tex:not return upon encountering the first non-positive diagonal.  In this case,\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/scratch/openblas-85636ff1a015d04d3a8f960bc644b85ee5157135/lapack-netlib/DOCS/lawn81.tex:\\setcounter{tocdepth}{3}\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/scratch/openblas-85636ff1a015d04d3a8f960bc644b85ee5157135/lapack-netlib/DOCS/lawn81.tex:\\setcounter{secnumdepth}{3}\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/scratch/openblas-85636ff1a015d04d3a8f960bc644b85ee5157135/lapack-netlib/DOCS/lawn81.tex:If you encountered failures in this phase of the testing process, please\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/scratch/openblas-85636ff1a015d04d3a8f960bc644b85ee5157135/lapack-netlib/DOCS/lawn81.tex:If you encountered failures in this phase of the testing process, please\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/scratch/openblas-85636ff1a015d04d3a8f960bc644b85ee5157135/lapack-netlib/DOCS/lawn81.tex:If you encounter failures in any phase of the timing process, please\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/scratch/openblas-85636ff1a015d04d3a8f960bc644b85ee5157135/lapack-netlib/DOCS/lawn81.tex:These input files time the BLAS using the matrix shapes encountered\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/scratch/openblas-85636ff1a015d04d3a8f960bc644b85ee5157135/lapack-netlib/DOCS/lawn81.tex:timing LAPACK.  If you encountered failures in any phase of the \n",
      "/home/ctroupin/Software/julia-0.6.0/deps/scratch/openblas-85636ff1a015d04d3a8f960bc644b85ee5157135/lapack-netlib/DOCS/lawn81.tex:encountered in our own experience with LAPACK.  A more detailed list\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/scratch/openblas-85636ff1a015d04d3a8f960bc644b85ee5157135/lapack-netlib/DOCS/lawn81.tex:of machine-dependent problems, bugs, and compiler errors encountered\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/libunwind-1.1-julia2/doc/unw_step.tex:  (``program-counter'') of the next stack frame is invalid (e.g., not\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/libunwind-1.1-julia2/doc/libunwind-ia64.tex:  ``program counter'') of the current stack frame.  Given this value,\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/libunwind-1.1-julia2/doc/libunwind.tex:(IP), sometimes also known as the ``program counter'', and the stack\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/mpfr-3.1.5/doc/texinfo.tex:% This is the counter used by @enumerate, which is really @itemize\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/mpfr-3.1.5/doc/texinfo.tex:% we again encounter the problem the 1sp was intended to solve.\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/mpfr-3.1.5/doc/texinfo.tex:      \\global\\colcount=0 % Reset the column counter.\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/mpfr-3.1.5/doc/texinfo.tex:% This counter is funny since it counts through charcodes of letters A, B, ...\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/mpfr-3.1.5/doc/texinfo.tex:% @chapter, @appendix, @unnumbered.  Increment top-level counter, reset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/mpfr-3.1.5/doc/texinfo.tex:% all lower-level sectioning counters to zero.\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/mpfr-3.1.5/doc/texinfo.tex:% If we encounter &foo, then turn on ()-hacking afterwards\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/mpfr-3.1.5/doc/texinfo.tex:% We keep a separate counter for each FLOATTYPE, which we reset at each\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/mpfr-3.1.5/doc/texinfo.tex:% The parameter is the control sequence identifying the counter we are\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/fftw-3.3.6-pl1/doc/texinfo.tex:% This is the counter used by @enumerate, which is really @itemize\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/fftw-3.3.6-pl1/doc/texinfo.tex:% we again encounter the problem the 1sp was intended to solve.\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/fftw-3.3.6-pl1/doc/texinfo.tex:      \\global\\colcount=0 % Reset the column counter.\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/fftw-3.3.6-pl1/doc/texinfo.tex:% This counter is funny since it counts through charcodes of letters A, B, ...\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/fftw-3.3.6-pl1/doc/texinfo.tex:% @chapter, @appendix, @unnumbered.  Increment top-level counter, reset\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/fftw-3.3.6-pl1/doc/texinfo.tex:% all lower-level sectioning counters to zero.\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/fftw-3.3.6-pl1/doc/texinfo.tex:% If we encounter &foo, then turn on ()-hacking afterwards\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/fftw-3.3.6-pl1/doc/texinfo.tex:% We keep a separate counter for each FLOATTYPE, which we reset at each\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/fftw-3.3.6-pl1/doc/texinfo.tex:% The parameter is the control sequence identifying the counter we are\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/gmp-6.1.2/doc/texinfo.tex:% This is the counter used by @enumerate, which is really @itemize\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/gmp-6.1.2/doc/texinfo.tex:% we again encounter the problem the 1sp was intended to solve.\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/gmp-6.1.2/doc/texinfo.tex:      \\global\\colcount=0 % Reset the column counter.\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/gmp-6.1.2/doc/texinfo.tex:% This counter is funny since it counts through charcodes of letters A, B, ...\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/gmp-6.1.2/doc/texinfo.tex:% @chapter, @appendix, @unnumbered.  Increment top-level counter, reset\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/gmp-6.1.2/doc/texinfo.tex:% all lower-level sectioning counters to zero.\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/gmp-6.1.2/doc/texinfo.tex:% If we encounter &foo, then turn on ()-hacking afterwards\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/gmp-6.1.2/doc/texinfo.tex:% We keep a separate counter for each FLOATTYPE, which we reset at each\n",
      "/home/ctroupin/Software/julia-0.6.0/deps/srccache/gmp-6.1.2/doc/texinfo.tex:% The parameter is the control sequence identifying the counter we are\n",
      "/home/ctroupin/Software/Python-3.6.0/Modules/_ctypes/libffi/texinfo.tex:% This is the counter used by @enumerate, which is really @itemize\n",
      "/home/ctroupin/Software/Python-3.6.0/Modules/_ctypes/libffi/texinfo.tex:% we again encounter the problem the 1sp was intended to solve.\n",
      "/home/ctroupin/Software/Python-3.6.0/Modules/_ctypes/libffi/texinfo.tex:      \\global\\colcount=0 % Reset the column counter.\n",
      "/home/ctroupin/Software/Python-3.6.0/Modules/_ctypes/libffi/texinfo.tex:% This counter is funny since it counts through charcodes of letters A, B, ...\n",
      "/home/ctroupin/Software/Python-3.6.0/Modules/_ctypes/libffi/texinfo.tex:% @chapter, @appendix, @unnumbered.  Increment top-level counter, reset\n",
      "/home/ctroupin/Software/Python-3.6.0/Modules/_ctypes/libffi/texinfo.tex:% all lower-level sectioning counters to zero.\n",
      "/home/ctroupin/Software/Python-3.6.0/Modules/_ctypes/libffi/texinfo.tex:% If we encounter &foo, then turn on ()-hacking afterwards\n",
      "/home/ctroupin/Software/Python-3.6.0/Modules/_ctypes/libffi/texinfo.tex:% We keep a separate counter for each FLOATTYPE, which we reset at each\n",
      "/home/ctroupin/Software/Python-3.6.0/Modules/_ctypes/libffi/texinfo.tex:% The parameter is the control sequence identifying the counter we are\n",
      "/home/ctroupin/Software/nco/autobld/texinfo.tex:% This is the counter used by @enumerate, which is really @itemize\n",
      "/home/ctroupin/Software/nco/autobld/texinfo.tex:% we again encounter the problem the 1sp was intended to solve.\n",
      "/home/ctroupin/Software/nco/autobld/texinfo.tex:      \\global\\colcount=0 % Reset the column counter.\n",
      "/home/ctroupin/Software/nco/autobld/texinfo.tex:% This counter is funny since it counts through charcodes of letters A, B, ...\n",
      "/home/ctroupin/Software/nco/autobld/texinfo.tex:% @chapter, @appendix, @unnumbered.  Increment top-level counter, reset\n",
      "/home/ctroupin/Software/nco/autobld/texinfo.tex:% all lower-level sectioning counters to zero.\n",
      "/home/ctroupin/Software/nco/autobld/texinfo.tex:% If we encounter &foo, then turn on ()-hacking afterwards\n",
      "/home/ctroupin/Software/nco/autobld/texinfo.tex:% We keep a separate counter for each FLOATTYPE, which we reset at each\n",
      "/home/ctroupin/Software/nco/autobld/texinfo.tex:% The parameter is the control sequence identifying the counter we are\n",
      "/home/ctroupin/Software/esmf/src/Infrastructure/Attribute/doc/Attribute_implnotes.tex:The specification of a list of PETs that are to be used as the basis for the update is a key feature of this interface.  This allows a many-to-many communication, as well as the direct specification of which PETs are to be updated and which are to be used as the \"real\" values.  The information is basically transported from the Attributes on the PETs specified in the rootList to their counterparts on the PETs which are not specified in the rootList.  This means that care must be taken to ensure that the data on the PETs in the rootList is consistent.\n",
      "/home/ctroupin/Software/esmf/src/Infrastructure/LogErr/doc/LogErr_ccwrapper.tex:  \\subsubsection [C\\_ESMF\\_LogSetHaltOnErr] {C\\_ESMF\\_LogSetHaltOnErr - program halts on encountering an error}\n",
      "/home/ctroupin/Software/esmf/src/Infrastructure/LogErr/doc/LogErr_ccwrapper.tex:  \\subsubsection [C\\_ESMF\\_LogSetHaltOnWarn] {C\\_ESMF\\_LogSetHaltOnWarn - program halts on encountering a warning}\n",
      "/home/ctroupin/Software/esmf/src/Infrastructure/Field/doc/Field_implnotes.tex:a unique object counter is maintained in the Base object class, and if\n",
      "/home/ctroupin/Software/esmf/src/Infrastructure/Field/doc/Field_implnotes.tex:created the same number of objects, that the counters on different PETs\n",
      "/home/ctroupin/Software/esmf/src/Infrastructure/Regrid/doc/Regrid_implnotes.tex:     where $C_{nk}$ is the counterclockwise path around the region $A_{nk}$.\n",
      "/home/ctroupin/Software/esmf/src/Infrastructure/Mesh/doc/Mesh_options.tex:of the polygon (e.g. for a pentagon use 5). The connectivity for a polygon should be specified in counter-clockwise order.\n",
      "/home/ctroupin/Software/esmf/src/addon/NUOPC/doc/NUOPC_Namespaces.tex:\\item The bondLevel is incremented by one counter for each cross-wise match between namespaces. (Considering that the bondLevel starts out as 1 for any Field pair with matching standard names, the maximum bondLevel that can be reached is 3.)\n",
      "/home/ctroupin/Software/esmf/src/addon/NUOPC/doc/NUOPC_ConnectionOptions.tex:     {\\tt unmappedaction} & The action to take when unmapped destination elements are encountered.& single & {\\tt ignore}(default), {\\tt error}\\\\ \\hline\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/GMAO_mpeu/doc/AppendixPrologue.tex:       public :: StringLinkedList_count\t! counter\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/GMAO_mpeu/doc/ErrorHandling.tex:When a problem is encountered, an error message is printed out and \n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/GMAO_mpeu/doc/PackageOverview.tex:\\setcounter{secnumdepth}{5}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Preamble.tex:\\setcounter{secnumdepth}{5}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Preamble.tex:\\setcounter{tocdepth}{1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Preamble.tex:% New counters\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Preamble.tex:\\newcounter{genct}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Preamble.tex:\\newcounter{grdct}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Preamble.tex:\\newcounter{sttct}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Preamble.tex:\\setcounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Preamble.tex:\\setcounter{grdct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Preamble.tex:\\setcounter{sttct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:\\texttt{Clock} is used to pass the simulation time counter to the component\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:  \\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:\\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/esmf/src/addon/MAPL/MAPL_Base/TeX/MAPL_Intro.tex:\\addtocounter{genct}{1}\n",
      "/home/ctroupin/Software/PythonEnvs/Drifter/lib/python2.7/site-packages/scipy/linalg/src/id_dist/doc/doc.tex:as a somewhat counterintuitive consequence, many must be randomized.\n",
      "/home/ctroupin/Software/PythonEnvs/CLQ-Statistics/lib/python2.7/site-packages/scipy/linalg/src/id_dist/doc/doc.tex:as a somewhat counterintuitive consequence, many must be randomized.\n",
      "/home/ctroupin/Publis/201712_MedSissy/MedSeaAtlas_20180130.tex:The Data Interpolating Variational Analysis (DIVA) is a method designed to perform spatial interpolation (analysis) of sparse and heterogeneously distributed and noisy data into a regular grid in an optimal way. The basic idea of the variational analysis is to determine a continuous filed approximating data and exhibiting small spatial variations. In other words, the target of the analysis is defined as the smoothest fields that respects the consistency with the observations and a priori knowledge of the background field over the domain of interest. To do so, a cost function that takes into account the distance between the reconstructed field and the observations and the regularity of the field is minimised. The solution of the minimisation problem is obtained through a finite-element technique \\citep{RIXEN00}. The main advantage is that the computational cost is independent of the number of data analyzed, instead it depends on the number of degrees of freedom i.e. on the size of the finite-element mesh. The mesh takes into account the complexity of the geometry of the domain without having to separate sub-basins prior to the interpolation and automatically prohibiting correlations across land barriers. Among other major advantages of the method, DIVA can take into account dynamic constraints allowing for anisotropic spatial correlation. Tools to generate the finite element mesh are provided as well as tools to optimize the parameters of the analysis. The signal-to-noise ratio is optimized by a Generalized Cross Validation (GCV) technique \\citep{BRANKART96} while the correlation length is estimated by comparing the relation between the empirical data covariance and the distance against its theoretical counterpart \\citep{TROUPIN17}. \n",
      "/home/ctroupin/Publis/201712_MedSissy/MedSeaAtlas.tex:The Data Interpolating Variational Analysis (DIVA) is a method designed to perform spatial interpolation (analysis) of sparse and heterogeneously distributed and noisy data into a regular grid in an optimal way. The basic idea of the variational analysis is to determine a continuous filed approximating data and exhibiting small spatial variations. In other words, the target of the analysis is defined as the smoothest fields that respects the consistency with the observations and a priori knowledge of the background field over the domain of interest. To do so, a cost function that takes into account the distance between the reconstructed field and the observations and the regularity of the field is minimised. The solution of the minimisation problem is obtained through a finite-element technique \\citep{RIXEN00}. The main advantage is that the computational cost is independent of the number of data analyzed, instead it depends on the number of degrees of freedom i.e. on the size of the finite-element mesh. The mesh takes into account the complexity of the geometry of the domain without having to separate sub-basins prior to the interpolation and automatically prohibiting correlations across land barriers. Among other major advantages of the method, DIVA can take into account dynamic constraints allowing for anisotropic spatial correlation. Tools to generate the finite element mesh are provided as well as tools to optimize the parameters of the analysis. The signal-to-noise ratio is optimized by a Generalized Cross Validation (GCV) technique \\citep{BRANKART96} while the correlation length is estimated by comparing the relation between the empirical data covariance and the distance against its theoretical counterpart \\citep{TROUPIN17}. \n",
      "/home/ctroupin/Publis/201712_MedSissy/MedSeaAtlas_20180129.tex:The Data Interpolating Variational Analysis (DIVA) is a method designed to perform spatial interpolation (analysis) of sparse and heterogeneously distributed and noisy data into a regular grid in an optimal way. The basic idea of the variational analysis is to determine a continuous filed approximating data and exhibiting small spatial variations. In other words, the target of the analysis is defined as the smoothest fields that respects the consistency with the observations and a priori knowledge of the background field over the domain of interest. To do so, a cost function that takes into account the distance between the reconstructed field and the observations and the regularity of the field is minimised. The solution of the minimisation problem is obtained through a finite-element technique \\citep{RIXEN00}. The main advantage is that the computational cost is independent of the number of data analyzed, instead it depends on the number of degrees of freedom i.e. on the size of the finite-element mesh. The mesh takes into account the complexity of the geometry of the domain without having to separate sub-basins prior to the interpolation and automatically prohibiting correlations across land barriers. Among other major advantages of the method, DIVA can take into account dynamic constraints allowing for anisotropic spatial correlation. Tools to generate the finite element mesh are provided as well as tools to optimize the parameters of the analysis. The signal-to-noise ratio is optimized by a Generalized Cross Validation (GCV) technique \\citep{BRANKART96} while the correlation length is estimated by comparing the relation between the empirical data covariance and the distance against its theoretical counterpart \\citep{TROUPIN17}. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ctroupin/Publis/201712_MedSissy/MedSeaAtlas_20180201.tex:The Data Interpolating Variational Analysis (DIVA) is a method designed to perform spatial interpolation (analysis) of sparse and heterogeneously distributed and noisy data into a regular grid in an optimal way. The basic idea of the variational analysis is to determine a continuous filed approximating data and exhibiting small spatial variations. In other words, the target of the analysis is defined as the smoothest fields that respects the consistency with the observations and a priori knowledge of the background field over the domain of interest. To do so, a cost function that takes into account the distance between the reconstructed field and the observations and the regularity of the field is minimised. The solution of the minimisation problem is obtained through a finite-element technique \\citep{RIXEN00}. The main advantage is that the computational cost is independent of the number of data analyzed, instead it depends on the number of degrees of freedom i.e. on the size of the finite-element mesh. The mesh takes into account the complexity of the geometry of the domain without having to separate sub-basins prior to the interpolation and automatically prohibiting correlations across land barriers. Among other major advantages of the method, DIVA can take into account dynamic constraints allowing for anisotropic spatial correlation. Tools to generate the finite element mesh are provided as well as tools to optimize the parameters of the analysis. The signal-to-noise ratio is optimized by a Generalized Cross Validation (GCV) technique \\citep{BRANKART96} while the correlation length is estimated by comparing the relation between the empirical data covariance and the distance against its theoretical counterpart \\citep{TROUPIN17}. \n",
      "/home/ctroupin/Publis/201712_MedSissy/MedSeaAtlas_20180131.tex:The Data Interpolating Variational Analysis (DIVA) is a method designed to perform spatial interpolation (analysis) of sparse and heterogeneously distributed and noisy data into a regular grid in an optimal way. The basic idea of the variational analysis is to determine a continuous filed approximating data and exhibiting small spatial variations. In other words, the target of the analysis is defined as the smoothest fields that respects the consistency with the observations and a priori knowledge of the background field over the domain of interest. To do so, a cost function that takes into account the distance between the reconstructed field and the observations and the regularity of the field is minimised. The solution of the minimisation problem is obtained through a finite-element technique \\citep{RIXEN00}. The main advantage is that the computational cost is independent of the number of data analyzed, instead it depends on the number of degrees of freedom i.e. on the size of the finite-element mesh. The mesh takes into account the complexity of the geometry of the domain without having to separate sub-basins prior to the interpolation and automatically prohibiting correlations across land barriers. Among other major advantages of the method, DIVA can take into account dynamic constraints allowing for anisotropic spatial correlation. Tools to generate the finite element mesh are provided as well as tools to optimize the parameters of the analysis. The signal-to-noise ratio is optimized by a Generalized Cross Validation (GCV) technique \\citep{BRANKART96} while the correlation length is estimated by comparing the relation between the empirical data covariance and the distance against its theoretical counterpart \\citep{TROUPIN17}. \n",
      "/home/ctroupin/Publis/201712_MedSissy/MedSeaAtlas_20180129_2columns.tex:The Data Interpolating Variational Analysis (DIVA) is a method designed to perform spatial interpolation (analysis) of sparse and heterogeneously distributed and noisy data into a regular grid in an optimal way. The basic idea of the variational analysis is to determine a continuous filed approximating data and exhibiting small spatial variations. In other words, the target of the analysis is defined as the smoothest fields that respects the consistency with the observations and a priori knowledge of the background field over the domain of interest. To do so, a cost function that takes into account the distance between the reconstructed field and the observations and the regularity of the field is minimised. The solution of the minimisation problem is obtained through a finite-element technique \\citep{RIXEN00}. The main advantage is that the computational cost is independent of the number of data analyzed, instead it depends on the number of degrees of freedom i.e. on the size of the finite-element mesh. The mesh takes into account the complexity of the geometry of the domain without having to separate sub-basins prior to the interpolation and automatically prohibiting correlations across land barriers. Among other major advantages of the method, DIVA can take into account dynamic constraints allowing for anisotropic spatial correlation. Tools to generate the finite element mesh are provided as well as tools to optimize the parameters of the analysis. The signal-to-noise ratio is optimized by a Generalized Cross Validation (GCV) technique \\citep{BRANKART96} while the correlation length is estimated by comparing the relation between the empirical data covariance and the distance against its theoretical counterpart \\citep{TROUPIN17}. \n",
      "/home/ctroupin/Publis/201703_AlborexData/latex/AlborexData201703.tex:In the context of mesoscale and submesoscale interactions, the AlborEx dataset constitutes a particularly valuable source of information to infer mechanisms, evaluate vertical transport and establish relationships between the thermal and haline structures and the biogeochemical variable evolution in a region characterised by strong horizontal gradients due to the encounter of Atlantic and Mediterranean Waters.\n",
      "/home/ctroupin/Publis/Older/DivaMLD_OS_2009/DivaMLD.tex:\\addtocounter{figure}{-1}\\renewcommand{\\thefigure}{\\arabic{figure}a}\n",
      "/home/ctroupin/Publis/Older/FilamentCAIBEX_JGR_2010/eddyfilamentJGR2010.tex:measurement (periodically-forced barotropic tides are a counter-example). \n",
      "/home/ctroupin/Publis/Older/DivaGMD2013/trunk/divaGMD2013.tex:\\addtocounter{figure}{-1}\\renewcommand{\\thefigure}{\\arabic{figure}a}\n",
      "/home/ctroupin/Publis/AtlanticTemperature2010/final_September2010/SSTanomalyTroupinMachin.tex:In the subtropical northeast Atlantic Ocean, the seasonal cycle of physical properties in surface layers is mainly driven by air-sea interactions, namely wind stress and net heat flux. In winter the net heat flux reaches negative values (i.e. transfer from ocean to atmosphere), responsible for the erosion of the thermocline. A late winter phytoplankton bloom is associated to this physical process \\cite{YODER93}. In summer, Trade winds intensify due to the northward motion of the Azores High \\cite{WOOSTER76}, while the net heat flux reaches its maximum. The result of these two counteracting processes is a strong stratification of the ocean surface layers. A shallow mixed layer prevents the upward injection of nutrients from deeper waters. Recent observations depict significant changes of the described seasonal cycle during the first months of 2010. It is of primary importance to examine these changes, because of the coupling between biological and physical cycles \\cite{ARISTEGUI01,TROUPIN10} and the influence of SST on the hurricane activity in the Atlantic Ocean \\cite{GOLDENBERG2001}. \n",
      "/home/ctroupin/Publis/AtlanticTemperature2010/poster/SSTanomaliesPoster.tex:%\\newcounter{figure}\n",
      "/home/ctroupin/Publis/AtlanticTemperature2010/poster/SSTanomaliesPoster.tex:\\setcounter{figure}{1}\n",
      "/home/ctroupin/Publis/AtlanticTemperature2010/poster/SSTanomaliesPoster.tex:  \\stepcounter{figure}\n",
      "/home/ctroupin/Publis/AtlanticTemperature2010/poster/SSTanomaliesPoster2.tex:%\\newcounter{figure}\n",
      "/home/ctroupin/Publis/AtlanticTemperature2010/poster/SSTanomaliesPoster2.tex:\\setcounter{figure}{1}\n",
      "/home/ctroupin/Publis/AtlanticTemperature2010/poster/SSTanomaliesPoster2.tex:  \\stepcounter{figure}\n",
      "/home/ctroupin/Publis/AtlanticTemperature2010/poster/SSTanomaliesPosterIODE2011.tex:%\\newcounter{figure}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ctroupin/Publis/AtlanticTemperature2010/poster/SSTanomaliesPosterIODE2011.tex:\\setcounter{figure}{1}\n",
      "/home/ctroupin/Publis/AtlanticTemperature2010/poster/SSTanomaliesPosterIODE2011.tex:  \\stepcounter{figure}\n",
      "/home/ctroupin/Publis/AtlanticTemperature2010/final_December2010/TemperatureHurricanesTroupinMachin.tex:In the subtropical northeast Atlantic Ocean, the seasonal cycle of physical properties in surface layers is mainly driven by air-sea interactions, namely wind stress and net heat flux. In winter the net heat flux reaches negative values (i.e. transfer from ocean to atmosphere), responsible for the erosion of the thermocline. A late winter phytoplankton bloom is associated to this physical process \\cite{YODER93}. In summer, Trade winds intensify due to the northward motion of the Azores High \\cite{WOOSTER76}, while the net heat flux reaches its maximum. The result of these two counteracting processes is a strong stratification of the ocean surface layers. A shallow mixed layer prevents the upward injection of nutrients from deeper waters. Recent observations depict significant changes of the described seasonal cycle during the first months of 2010. It is of primary importance to examine these changes, because of the coupling between biological and physical cycles \\cite{ARISTEGUI01,TROUPIN10} and the influence of SST on the hurricane activity in the Atlantic Ocean \\cite{GOLDENBERG2001}. \n",
      "/home/ctroupin/Publis/AtlanticTemperature2010/TeXfiles/SSTanomaly2010V3.tex:In the subtropical northeast Atlantic Ocean, the seasonal cycle of physical properties is mainly driven by air-sea interactions, namely wind stress and net heat flux. Winter is characterized by negative heat fluxes (i.e. from ocean to atmosphere) and weak winds, responsible for the erosion of the thermocline. A late winter phytoplankton bloom is associated to this physical process \\citep[e.g.][]{DELEON73,HERNANDEZLEON84,HERNANDEZLEON04}. In summer, Trade winds intensify due to the northward motion of the Azores High \\citep{WOOSTER76}, while the net heat flux reaches its maximum. The result of these two counteracting processes is a strong stratification of the ocean surface layers. A shallow mixed layer prevents the injection of nutrients from deeper waters. Recent observations obtained from open databases depict significant changes of the described seasonal cycle during the first months of 2010. It is of primary importance to examine these changes, because of the coupling between biological and physical cycles \\citep{ARISTEGUI01,TROUPIN10} and the influence of SST on the hurricane activity in the Atlantic Ocean \\citep[e.g.][]{GOLDENBERG2001}. \n",
      "/home/ctroupin/Publis/AtlanticTemperature2010/TeXfiles/SSTanomaly2010V2.tex:In the subtropical northeast Atlantic Ocean, the seasonal cycle of physical properties is mainly driven by air-sea interactions, namely wind stress and net heat flux. Winter is characterized by negative heat fluxes (i.e. from ocean to atmosphere) and weak winds, responsible for the erosion of the thermocline. A late winter phytoplankton bloom is associated to this physical process \\citep[e.g.][]{DELEON73,HERNANDEZLEON84,HERNANDEZLEON04}. In summer, Trade winds intensify due to the northward motion of the Azores High \\citep{WOOSTER76}, while the net heat flux reaches its maximum. The result of these two counteracting processes is a strong stratification of the ocean surface layers. A shallow mixed layer prevents the injection of nutrients from deeper waters. Recent observations obtained from open databases depict significant changes of the described seasonal cycle during the first months of 2010. It is of primary importance to examine these changes, because of the coupling between biological and physical cycles \\citep{ARISTEGUI01,TROUPIN10} and the influence of SST on the hurricane activity in the Atlantic Ocean \\citep[e.g.][]{GOLDENBERG2001}. \n",
      "/home/ctroupin/Publis/AtlanticTemperature2010/TeXfiles/SSTanomaly2010V4.tex:In the subtropical northeast Atlantic Ocean, the seasonal cycle of physical properties is mainly driven by air-sea interactions, namely wind stress and net heat flux. In winter the net heat flux reaches negative values (i.e. transfert from ocean to atmosphere), responsible for the erosion of the thermocline. A late winter phytoplankton bloom is associated to this physical process \\citep[e.g.][]{DELEON73,HERNANDEZLEON84,HERNANDEZLEON04}. In summer, Trade winds intensify due to the northward motion of the Azores High \\citep{WOOSTER76}, while the net heat flux reaches its maximum. The result of these two counteracting processes is a strong stratification of the ocean surface layers. A shallow mixed layer prevents the injection of nutrients from deeper waters. Recent observations depict significant changes of the described seasonal cycle during the first months of 2010. It is of primary importance to examine these changes, because of the coupling between biological and physical cycles \\citep{ARISTEGUI01,TROUPIN10} and the influence of SST on the hurricane activity in the Atlantic Ocean \\citep[e.g.][]{GOLDENBERG2001}. \n",
      "/home/ctroupin/Publis/Review/20170916_PhDYeray/ReviewYeray.tex:\\newcounter{enumTemp}\n",
      "/home/ctroupin/Publis/Review/20170916_PhDYeray/ReviewYeray.tex: \\setcounter{enumTemp}{\\theenumi}\n",
      "/home/ctroupin/Publis/Review/20170916_PhDYeray/ReviewYeray.tex:\\setcounter{enumi}{\\theenumTemp}\n",
      "/home/ctroupin/Publis/Review/20170916_PhDYeray/ReviewYeray.tex:\\setcounter{enumTemp}{\\theenumi}\n",
      "/home/ctroupin/Publis/Review/20170916_PhDYeray/ReviewYeray.tex:\\setcounter{enumi}{\\theenumTemp}\n",
      "/home/ctroupin/Publis/Review/20170916_PhDYeray/ReviewYeray.tex:\\setcounter{enumTemp}{\\theenumi}\n",
      "/home/ctroupin/Publis/Review/20170916_PhDYeray/ReviewYeray.tex:\\setcounter{enumi}{\\theenumTemp}\n",
      "/home/ctroupin/Publis/Review/20170916_PhDYeray/ReviewYeray.tex: \\setcounter{enumTemp}{\\theenumi}\n",
      "/home/ctroupin/Publis/Review/20170916_PhDYeray/ReviewYeray.tex:\\setcounter{enumi}{\\theenumTemp}\n",
      "/home/ctroupin/Publis/Review/20170916_PhDYeray/typosYeray.tex:\\newcounter{enumTemp}\n",
      "/home/ctroupin/Publis/Review/20170916_PhDYeray/typosYeray.tex:\\setcounter{enumTemp}{\\theenumi}\n",
      "/home/ctroupin/Publis/Review/20170916_PhDYeray/typosYeray.tex:\\setcounter{enumi}{\\theenumTemp}\n",
      "/home/ctroupin/Publis/Review/20170916_PhDYeray/typosYeray.tex: \\setcounter{enumTemp}{\\theenumi}\n",
      "/home/ctroupin/Publis/Review/20170916_PhDYeray/typosYeray.tex:\\setcounter{enumi}{\\theenumTemp}\n",
      "/home/ctroupin/Publis/Review/20170925_PhDBarbara/ReviewBarbara.tex:\\newcounter{enumTemp}\n",
      "/home/ctroupin/Publis/Review/20170925_PhDBarbara/ReviewBarbara.tex:For instance, Section 2.1 starts with a definition: \"Intrathermocline eddies are\". \\setcounter{enumTemp}{\\theenumi}\n",
      "/home/ctroupin/Publis/Review/20170925_PhDBarbara/ReviewBarbara.tex:\\setcounter{enumi}{\\theenumTemp}\n",
      "/home/ctroupin/Publis/Review/20170925_PhDBarbara/ReviewBarbara.tex:\\item The General Introduction starts with \"Mesoscale oceanic structures\", but mesoscale is not defined at all \\where{p 3} \\setcounter{enumTemp}{\\theenumi}\n",
      "/home/ctroupin/Publis/Review/20170925_PhDBarbara/ReviewBarbara.tex:\\setcounter{enumi}{\\theenumTemp}\n",
      "/home/ctroupin/Publis/Review/20170925_PhDBarbara/ReviewBarbara.tex:\\item About SWOT: do you think it can be easily used for a product such as ARMOR3D? \\where{p 32} \\setcounter{enumTemp}{\\theenumi}\n",
      "/home/ctroupin/Publis/Review/20170925_PhDBarbara/ReviewBarbara.tex:\\setcounter{enumi}{\\theenumTemp}\n",
      "/home/ctroupin/Publis/Review/20170925_PhDBarbara/ReviewBarbara.tex:\\setcounter{enumTemp}{\\theenumi}\n",
      "/home/ctroupin/Publis/Review/20170925_PhDBarbara/ReviewBarbara.tex:\\setcounter{enumi}{\\theenumTemp}\n",
      "/home/ctroupin/Publis/Review/20170925_PhDBarbara/ReviewBarbara.tex:\\setcounter{enumTemp}{\\theenumi}\n",
      "/home/ctroupin/Publis/Review/20170925_PhDBarbara/ReviewBarbara.tex:\\setcounter{enumi}{\\theenumTemp}\n",
      "/home/ctroupin/Publis/Review/20170925_PhDBarbara/ReviewBarbara.tex:\\setcounter{enumTemp}{\\theenumi}\n",
      "/home/ctroupin/Publis/Review/20170925_PhDBarbara/ReviewBarbara.tex:\\setcounter{enumi}{\\theenumTemp}\n",
      "/home/ctroupin/Publis/Review/20170925_PhDBarbara/ReviewBarbara.tex:\\setcounter{enumTemp}{\\theenumi}\n",
      "/home/ctroupin/Publis/Review/20170925_PhDBarbara/ReviewBarbara.tex:\\setcounter{enumi}{\\theenumTemp}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ctroupin/Publis/Review/20170925_PhDBarbara/ReviewBarbara.tex:\\item \\setcounter{enumTemp}{\\theenumi}\n",
      "/home/ctroupin/Publis/Review/ReviewJMS2012/notes4review.tex:The author proposes a clear, concise and focused manuscript dealing with a method designed to \"fill the gaps\" frequently encountered in oceanography. The method is an improvement on the method described in Schneider (2001). The examples to illustrate the method are well chosen, with an increasing complexity, while the results are adequately linked to physical processes.\n",
      "/home/ctroupin/Publis/Published/divand/diva-nd/divand.tex:%\\setcounter{totalnumber}{0}\n",
      "/home/ctroupin/Publis/Published/Fabian/flsevos.tex:%\\setcounter{totalnumber}{0}\n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/4orbi/DIVA2012OM.tex:The intrinsic advantages of the method are its natural way to take into account topographic and dynamic constraints (coasts, advection, \\ldots) and its capacity to handle large data sets, frequently encountered in oceanography. The method provides gridded fields in two dimensions, usually in horizontal layers. Three-dimension fields are obtained by stacking horizontal layers.\n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/CorrectionsJanuary2011/diva4.2paper2010E.tex:\\diva is a variational analysis tool designed to interpolate irregularly spaced and noisy data onto any desired location, in most cases on regular grids. A distinct advantage of \\diva compared to other analysis tools such as optimal interpolation is its natural way to take into account topographic effects and advection. Moreover, large data sets, frequently encountered in oceanography, do not constitute an obstacle to the application of \\diva. However, until now, only an approximate error-field estimate was available and only a unique overall length scale could be prescribed. Here we present some improvements brought to the variational analysis tool, allowing one to combine advection constraints, variable correlation length and full error calculation in an efficient way. Furthermore a data-quality control method is added and new tools for parameter optimisation are provided. The added value of these features are illustrated in the case of climatological salinity measurements in the Mediterranean Sea.\n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/CorrectionsJanuary2011/diva4.2paper2010E.tex:For the smallest value of $\\snr$ tested  (0.01), the generalised cross validator $\\Theta$ (which constitutes a measure of the quality of the analyse, as described in Sect.~\\ref{sec:cvgcv}) is 0.28 for GCV and 0.27 for CV and CV-rand. When $\\snr$ is increased, $\\Theta$ decreases and reaches a minimum dependent on the method: with GCV the optimal value is found for $\\snr=25.15$, while CV and CV-rand give $\\snr=4.02$ and $\\snr=4.38$, respectively. The relatively high values determined with these methods are due to the fact that data are not independent, in particular because of the redundancy of measurements made during cruises. A workaround of this issue may be the removal of data corresponding to one or several cruises for the GCV. However, this procedure would no be easily implemented, since the information allowing the distinction of cruises is not always available with the considered data bases. A similar issue was encountered by \\citet{TROUPIN10}: they worked with a constant $\\snr$ value to avoid the large variations of $\\snr$ from one layer/month to the other.\n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/CorrectionsJanuary2011/diva4.2paper2010E.tex:A realistic example using September salinity in the Mediterranean Sea at 30~m is presented and the various theoretical developments are illustrated. A set of 352 data points is put aside for statistics and validation concerns. The parameter estimation tools are applied in order to obtain optimal values for the $L$ and $\\snr$. The $\\snr$ value provided by the GCV turns out to be too high, leading to noisy analysed fields. This problem was also encountered in other application of \\diva and is due to the fact that the data are not independent. The value given by the CV is lower, so the corresponding analysis appears more realistic (i.e. with smoother gradient) than in the case with the signal-to-noise ratio provided by the GCV. The advection constraint, deduced from the velocity field of a numerical model, is assessed in a situation where all the data in a determined area are artificially removed. The advection permits to better reconstruct the field in this area, taking into account the propagation of the information with the current. The outlier criterion is also tested on the same data set: a group of data points of which the position or the value has been changed are successfully detected as suspect observations. Finally, a comparison with the OI method is made. It highlights similitude of both method at large distances from the coast and their difference in the coastal area.\n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/CorrectionsJanuary2011/diva4.2paper2010F.tex:\\diva is a variational analysis tool designed to interpolate irregularly spaced and noisy data onto any desired location, in most cases on regular grids. A distinct advantage of \\diva compared to other analysis tools such as optimal interpolation is its natural way to take into account topographic effects and advection. Moreover, large data sets, frequently encountered in oceanography, do not constitute an obstacle to the application of \\diva. However, until now, only an approximate error-field estimate was available and only a unique overall length scale could be prescribed. Here we present some improvements brought to the variational analysis tool, allowing one to combine advection constraints, variable correlation length and full error calculation in an efficient way. Furthermore a data-quality control method is added and new tools for parameter optimisation are provided. The added value of these features are illustrated in the case of climatological salinity measurements in the Mediterranean Sea.\n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/CorrectionsJanuary2011/diva4.2paper2010F.tex:For the smallest value of $\\snr$ tested  (0.01), the generalised cross-validator $\\Theta$ (which constitutes a measure of the quality of the analyse, as described in Sect.~\\ref{sec:cvgcv}) is 0.28 for GCV and 0.27 for CV and CV-rand. When $\\snr$ is increased, $\\Theta$ decreases and reaches a minimum dependent on the method: with GCV the optimal value is found for $\\snr=25.15$, while CV and CV-rand give $\\snr=4.02$ and $\\snr=4.38$, respectively. The relatively high values determined with these methods are due to the fact that data are not independent, in particular because of the redundancy of measurements made during cruises. A workaround of this issue may be the removal of data corresponding to one or several cruises for the GCV. However, this procedure would no be easily implemented, since the information allowing the distinction of cruises is not always available with the considered data bases. A similar issue was encountered by \\citet{TROUPIN10}: they worked with a constant $\\snr$ value to avoid the large variations of $\\snr$ from one layer/month to the other.\n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/CorrectionsJanuary2011/diva4.2paper2010F.tex:A realistic example using September salinity in the Mediterranean Sea at 30~m is presented and the various theoretical developments are illustrated. A set of 352 data points is put aside for statistics and validation concerns. The parameter estimation tools are applied in order to obtain optimal values for $L$ and $\\snr$. The $\\snr$ value provided by the GCV turns out to be too high, leading to noisy analysed fields. This problem was also encountered in other applications of \\diva and is due to the fact that the data are not independent. The value given by the CV is lower, so the corresponding analysis appears more realistic (i.e. with weaker gradients) than in the case with the signal-to-noise ratio provided by the GCV. The advection constraint, deduced from the velocity field of a numerical model, is assessed in a situation where all the data in a determined area are artificially removed. The advection permits to better reconstruct the field in this area, taking into account the propagation of the information with the current. The outlier criterion is also tested on the same data set: a group of data points of which the position or the value has been changed are successfully detected as suspect observations. Finally, a comparison with the OI method is made. It highlights the similarities of both methods at large distances from the coast and their difference in the coastal area.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ctroupin/Publis/Published/Diva_OM_2011/CorrectionsJanuary2011/diva4.2paper2010C.tex:\\diva is a variational analysis tool designed to interpolate irregularly spaced and noisy data into any desired location, in most cases on regular grids. A distinct advantage of \\diva compared to other analysis tools such as optimal interpolation is its natural way to take into account topographic effects and advection. Moreover, large data sets, frequently encountered in oceanography, do not constitute an obstacle to the application of \\diva. However, until now, only an approximate error-field estimate was available and only a unique overall length scale could be prescribed. Here we present some improvements brought to the variational analysis tool, allowing one to combine advection constraints, variable correlation length and full error calculation in an efficient way. Furthermore a data-quality control method is added and new tools for parameter optimisation are provided. The added value of these features are illustrated in the case of a climatological salinity measurements in the Mediterranean Sea.\n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/CorrectionsJanuary2011/diva4.2paper2010C.tex:For the smallest value of $\\snr$ tested  (0.01), the generalised cross validator $\\Theta$ (which constitutes a measure of the quality of the analyse, as described in Sect.~\\ref{sec:cvgcv}) is 0.28 for GCV and 0.27 for CV and CV-rand. When $\\snr$ is increased, $\\Theta$ decreases and reaches a minimum dependent on the method: with GCV the optimal value is found for $\\snr=25.15$, while CV and CV-rand give $\\snr=4.02$ and $\\snr=4.38$, respectively. The relatively high values determined with these methods are due to the fact that data are not independent, in particular because of the redundancy of measurements made during cruises. A workaround of this issue may be the removal of data corresponding to one or several cruises for the GCV. However, this procedure would no be easily implemented, since the information allowing the distinction of cruises is not always available. A similar issue was encountered by \\citet{TROUPIN10}: they worked with a constant $\\snr$ value to avoid the large variations of $\\snr$ from one layer/month to the other.\n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/CorrectionsJanuary2011/diva4.2paper2010C.tex:A realistic example using September salinity in the Mediterranean Sea at 30~m is presented and the various theoretical developments are illustrated. A set of 352 data points is put aside for statistics and validation concerns. The parameter estimation tools are applied in order to obtain optimal values for the $L$ and $\\snr$. The $\\snr$ value provided by the GCV turns out to be too high, leading to noisy analysed fields. This problem was also encountered in other application of \\diva and is due to the fact that the data are not independent. The value given by the CV is lower, so the corresponding analysis appears more realistic (i.e. with smoother gradient) than in the case with the signal-to-noise ratio provided by the GCV. The advection constraint, deduced from the velocity field of a numerical model, is assessed in a situation where all the data in a determined area are artificially removed. The advection permits to better reconstruct the field in this area, taking into account the propagation of the information with the current. The outlier criterion is also tested on the same data set: a group of data points of which the position or the value has been changed are successfully detected as suspect observations. Finally, a comparison with the OI method is made. It highlights similitude of both method at large distances from the coast and their difference in the coastal area.\n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/CorrectionsJanuary2011/diva4.2paper2010D.tex:\\diva is a variational analysis tool designed to interpolate irregularly spaced and noisy data onto any desired location, in most cases on regular grids. A distinct advantage of \\diva compared to other analysis tools such as optimal interpolation is its natural way to take into account topographic effects and advection. Moreover, large data sets, frequently encountered in oceanography, do not constitute an obstacle to the application of \\diva. However, until now, only an approximate error-field estimate was available and only a unique overall length scale could be prescribed. Here we present some improvements brought to the variational analysis tool, allowing one to combine advection constraints, variable correlation length and full error calculation in an efficient way. Furthermore a data-quality control method is added and new tools for parameter optimisation are provided. The added value of these features are illustrated in the case of climatological salinity measurements in the Mediterranean Sea.\n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/CorrectionsJanuary2011/diva4.2paper2010D.tex:For the smallest value of $\\snr$ tested  (0.01), the generalised cross validator $\\Theta$ (which constitutes a measure of the quality of the analyse, as described in Sect.~\\ref{sec:cvgcv}) is 0.28 for GCV and 0.27 for CV and CV-rand. When $\\snr$ is increased, $\\Theta$ decreases and reaches a minimum dependent on the method: with GCV the optimal value is found for $\\snr=25.15$, while CV and CV-rand give $\\snr=4.02$ and $\\snr=4.38$, respectively. The relatively high values determined with these methods are due to the fact that data are not independent, in particular because of the redundancy of measurements made during cruises. A workaround of this issue may be the removal of data corresponding to one or several cruises for the GCV. However, this procedure would no be easily implemented, since the information allowing the distinction of cruises is not always available with the considered data bases. A similar issue was encountered by \\citet{TROUPIN10}: they worked with a constant $\\snr$ value to avoid the large variations of $\\snr$ from one layer/month to the other.\n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/CorrectionsJanuary2011/diva4.2paper2010D.tex:A realistic example using September salinity in the Mediterranean Sea at 30~m is presented and the various theoretical developments are illustrated. A set of 352 data points is put aside for statistics and validation concerns. The parameter estimation tools are applied in order to obtain optimal values for the $L$ and $\\snr$. The $\\snr$ value provided by the GCV turns out to be too high, leading to noisy analysed fields. This problem was also encountered in other application of \\diva and is due to the fact that the data are not independent. The value given by the CV is lower, so the corresponding analysis appears more realistic (i.e. with smoother gradient) than in the case with the signal-to-noise ratio provided by the GCV. The advection constraint, deduced from the velocity field of a numerical model, is assessed in a situation where all the data in a determined area are artificially removed. The advection permits to better reconstruct the field in this area, taking into account the propagation of the information with the current. The outlier criterion is also tested on the same data set: a group of data points of which the position or the value has been changed are successfully detected as suspect observations. Finally, a comparison with the OI method is made. It highlights similitude of both method at large distances from the coast and their difference in the coastal area.\n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/FinalMarch2011OM/DIVA2011OM.tex:\\diva (Data Interpolating Variational Analysis) is a variational analysis tool designed to interpolate irregularly-spaced, noisy data onto any desired location, in most cases on regular grids. It is the combination of a particular methodology, based on the minimisation of a functional, and a numerically efficient resolution method, based on a finite elements solver. The intrinsic advantages of \\diva are its natural way to take into account topographic and dynamic constraints (coasts, advection, \\ldots) and its capacity to handle large data sets, frequently encountered in oceanography. \n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/FinalMarch2011OM/DIVA2011OM.tex:For the smallest value of $\\snr$ tested  (0.01), the generalised cross-validator $\\Theta$ (which constitutes a measure of the quality of the analyse, as described in Sect.~\\ref{sec:cvgcv}) is 0.28 for GCV and 0.27 for CV and CV-rand. When $\\snr$ is increased, $\\Theta$ decreases and reaches a minimum dependent on the method: with GCV the optimal value is found for $\\snr=25.15$, while CV and CV-rand give $\\snr=4.02$ and $\\snr=4.38$, respectively. The relatively high values determined with these methods are due to the fact that data are not independent, in particular because of the redundancy of measurements made during cruises. A workaround of this issue may be the removal of data corresponding to one or several cruises for the GCV. However, this procedure would no be easily implemented, since the information allowing the distinction of cruises is not always available with the considered data bases. A similar issue was encountered by \\citet{TROUPIN10}: they worked with a constant $\\snr$ value to avoid the large variations of $\\snr$ from one layer/month to the other.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ctroupin/Publis/Published/Diva_OM_2011/FinalMarch2011OM/DIVA2011OM.tex:A realistic example using September salinity in the Mediterranean Sea at 30~m has been presented and the various theoretical developments have been illustrated. A set of 352 data points was put aside for statistics and validation concerns. The parameter estimation tools are applied in order to obtain optimal values for $L$ and $\\snr$. The $\\snr$ value provided by the GCV turns out to be too high, leading to noisy analysed fields. This problem was also encountered in other applications of \\diva and is due to the fact that the observation errors of the data are not independent. The value given by the CV is lower, so the corresponding analysis appears more realistic (i.e., with weaker gradients) than in the case with the signal-to-noise ratio provided by the GCV. The advection constraint, deduced from the velocity field of a numerical model, is assessed in a situation where all the data in a determined area are artificially removed. The advection provides a better analysis in this area, taking into account the propagation of the information with the current. The outlier criterion is also tested on the same data set: a group of data points of which the position or the value has been changed are successfully detected as suspect observations. Finally, a comparison with the OI method is made. It highlights the similarities of both methods at large distances from the coast and their difference in the coastal area.\n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/FinalMarch2011OM/diva4.2paper2011.tex:\\diva is a variational analysis tool designed to interpolate irregularly-spaced, noisy data onto any desired location, in most cases on regular grids. It is the combination of a particular methodology, based on the minimisation of a functional, and a numerically efficient resolution method, based on a finite elements solver. The intrinsic advantages of \\diva are its natural way to take into account topographic and dynamic constraints (coasts, advection, \\ldots) and its capacity to handle large data sets, frequently encountered in oceanography. \n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/FinalMarch2011OM/diva4.2paper2011.tex:For the smallest value of $\\snr$ tested  (0.01), the generalised cross-validator $\\Theta$ (which constitutes a measure of the quality of the analyse, as described in Sect.~\\ref{sec:cvgcv}) is 0.28 for GCV and 0.27 for CV and CV-rand. When $\\snr$ is increased, $\\Theta$ decreases and reaches a minimum dependent on the method: with GCV the optimal value is found for $\\snr=25.15$, while CV and CV-rand give $\\snr=4.02$ and $\\snr=4.38$, respectively. The relatively high values determined with these methods are due to the fact that data are not independent, in particular because of the redundancy of measurements made during cruises. A workaround of this issue may be the removal of data corresponding to one or several cruises for the GCV. However, this procedure would no be easily implemented, since the information allowing the distinction of cruises is not always available with the considered data bases. A similar issue was encountered by \\citet{TROUPIN10}: they worked with a constant $\\snr$ value to avoid the large variations of $\\snr$ from one layer/month to the other.\n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/FinalMarch2011OM/diva4.2paper2011.tex:A realistic example using September salinity in the Mediterranean Sea at 30~m has been presented and the various theoretical developments have been illustrated. A set of 352 data points was put aside for statistics and validation concerns. The parameter estimation tools are applied in order to obtain optimal values for $L$ and $\\snr$. The $\\snr$ value provided by the GCV turns out to be too high, leading to noisy analysed fields. This problem was also encountered in other applications of \\diva and is due to the fact that the observation errors of the data are not independent. The value given by the CV is lower, so the corresponding analysis appears more realistic (i.e., with weaker gradients) than in the case with the signal-to-noise ratio provided by the GCV. The advection constraint, deduced from the velocity field of a numerical model, is assessed in a situation where all the data in a determined area are artificially removed. The advection provides a better analysis in this area, taking into account the propagation of the information with the current. The outlier criterion is also tested on the same data set: a group of data points of which the position or the value has been changed are successfully detected as suspect observations. Finally, a comparison with the OI method is made. It highlights the similarities of both methods at large distances from the coast and their difference in the coastal area.\n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/FinalMarch2011OM/DIVA2011OMb.tex:\\diva (Data Interpolating Variational Analysis) is a variational analysis tool designed to interpolate irregularly-spaced, noisy data onto any desired location, in most cases on regular grids. It is the combination of a particular methodology, based on the minimisation of a functional, and a numerically efficient resolution method, based on a finite elements solver. The intrinsic advantages of \\diva are its natural way to take into account topographic and dynamic constraints (coasts, advection, \\ldots) and its capacity to handle large data sets, frequently encountered in oceanography. \n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/FinalMarch2011OM/DIVA2011OMb.tex:For the smallest value of $\\snr$ tested  (0.01), the generalised cross-validator $\\Theta$ (which constitutes a measure of the quality of the analyse, as described in Sect.~\\ref{sec:cvgcv}) is 0.28 for GCV and 0.27 for CV and CV-rand. When $\\snr$ is increased, $\\Theta$ decreases and reaches a minimum dependent on the method: with GCV the optimal value is found for $\\snr=25.15$, while CV and CV-rand give $\\snr=4.02$ and $\\snr=4.38$, respectively. The relatively high values determined with these methods are due to the fact that data are not independent, in particular because of the redundancy of measurements made during cruises. A workaround of this issue may be the removal of data corresponding to one or several cruises for the GCV. However, this procedure would no be easily implemented, since the information allowing the distinction of cruises is not always available with the considered data bases. A similar issue was encountered by \\citet{TROUPIN10}: they worked with a constant $\\snr$ value to avoid the large variations of $\\snr$ from one layer/month to the other.\n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/FinalMarch2011OM/DIVA2011OMb.tex:A realistic example using September salinity in the Mediterranean Sea at 30~m has been presented and the various theoretical developments have been illustrated. A set of 352 data points was put aside for statistics and validation concerns. The parameter estimation tools are applied in order to obtain optimal values for $L$ and $\\snr$. The $\\snr$ value provided by the GCV turns out to be too high, leading to noisy analysed fields. This problem was also encountered in other applications of \\diva and is due to the fact that the observation errors of the data are not independent. The value given by the CV is lower, so the corresponding analysis appears more realistic (i.e., with weaker gradients) than in the case with the signal-to-noise ratio provided by the GCV. The advection constraint, deduced from the velocity field of a numerical model, is assessed in a situation where all the data in a determined area are artificially removed. The advection provides a better analysis in this area, taking into account the propagation of the information with the current. The outlier criterion is also tested on the same data set: a group of data points of which the position or the value has been changed are successfully detected as suspect observations. Finally, a comparison with the OI method is made. It highlights the similarities of both methods at large distances from the coast and their difference in the coastal area.\n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/FinalMarch2011OM/Diva2011CoverLetter.tex:\\noindent We believe that this interpolation method is of interest to the readers of Ocean Modelling, since it can be applied to any kind of sparse data (frequent in oceanography), even for huge data sets ( $>$ 1000000 data points) and circumvent some of the problems encountered with other widespread method, such as the optimal interpolation. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ctroupin/Publis/Published/Diva_OM_2011/RevisionNovember2011/DIVA2011OM_review.tex:The intrinsic advantages of the method are its natural way to take into account topographic and dynamic constraints (coasts, advection, \\ldots) and its capacity to handle large data sets, frequently encountered in oceanography. The method provides gridded fields in two dimensions, usually in horizontal layers. Three-dimension fields are obtained by stacking horizontal layers.\n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/RevisionNovember2011/DIVA2011OM_review_figures.tex:The intrinsic advantages of the method are its natural way to take into account topographic and dynamic constraints (coasts, advection, \\ldots) and its capacity to handle large data sets, frequently encountered in oceanography. The method provides gridded fields in two dimensions, usually in horizontal layers. Three-dimension fields are obtained by stacking horizontal layers.\n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/RevisionApril2012/DIVA2011OM_review3.tex:The intrinsic advantages of the method are its natural way to take into account topographic and dynamic constraints (coasts, advection, \\ldots) and its capacity to handle large data sets, frequently encountered in oceanography. The method provides gridded fields in two dimensions, usually in horizontal layers. Three-dimension fields are obtained by stacking horizontal layers.\n",
      "/home/ctroupin/Publis/Published/Diva_OM_2011/RevisionFeb2012/DIVA2011OM_review2.tex:The intrinsic advantages of the method are its natural way to take into account topographic and dynamic constraints (coasts, advection, \\ldots) and its capacity to handle large data sets, frequently encountered in oceanography. The method provides gridded fields in two dimensions, usually in horizontal layers. Three-dimension fields are obtained by stacking horizontal layers.\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/Final/Troupin_diva_JGR.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/Final/Troupin_diva_JGR.tex:%\\addtocounter{subfigure}{2}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/Final/Troupin_diva_JGR.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/Final/Troupin_diva_JGR.tex:%\\addtocounter{subfigure}{2}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/Final/Troupin_diva_JGR.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/Final/Troupin_diva_JGR.tex:%\\addtocounter{subfigure}{2}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/Final/Troupin_diva_JGR.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/Final/Troupin_diva_JGR.tex:%\\addtocounter{subfigure}{2}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/Final/Troupin_diva_JGR.tex:The difference between the two fields (with and without outliers) is mapped in Fig. \\ref{fig:salinityoutliers}, along with the suspect data locations. The first striking fact is that most of the suspect data are located near Newfoundland and Labrador shelves. As outlined in Sec.  \\ref{sec:datasources}, this zone is characterized by a strong variability, due to the encounter of Gulf Stream and Labrador Current. Nevertheless, the removal of numerous data in this region did not strongly affect the analyzed field. This is simply explained by the large number of measurements available (see Fig. \\ref{fig:datadensity}).\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/Final/Troupin_diva_JGR.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/Final/Troupin_diva_JGR.tex:\\addtocounter{subfigure}{2}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/Final/Troupin_diva_JGR.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/Final/Troupin_diva_JGR.tex:\\addtocounter{subfigure}{4}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/Final/Troupin_diva_JGR.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/Final/Troupin_diva_JGR.tex:\\addtocounter{subfigure}{6}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/Final/Troupin_diva_JGR.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/Final/Troupin_diva_JGR.tex:\\addtocounter{subfigure}{8}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/January2010/diva_JGR_final.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/January2010/diva_JGR_final.tex:%\\addtocounter{subfigure}{2}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/January2010/diva_JGR_final.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/January2010/diva_JGR_final.tex:%\\addtocounter{subfigure}{2}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/January2010/diva_JGR_final.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/January2010/diva_JGR_final.tex:%\\addtocounter{subfigure}{2}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/January2010/diva_JGR_final.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/January2010/diva_JGR_final.tex:%\\addtocounter{subfigure}{2}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/January2010/diva_JGR_final.tex:The difference between the two fields (with and without outliers) is mapped in Fig. \\ref{fig:salinityoutliers}, along with the suspect data locations. The first striking fact is that most of the suspect data are located near Newfoundland and Labrador shelves. As outlined in Sec.  \\ref{sec:datasources}, this zone is characterized by a strong variability, due to the encounter of Gulf Stream and Labrador Current. Nevertheless, the removal of numerous data in this region did not strongly affect the analyzed field. This is simply explained by the large number of measurements available (see Fig. \\ref{fig:datadensity}).\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/January2010/diva_JGR_final.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/January2010/diva_JGR_final.tex:%\\addtocounter{subfigure}{2}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/January2010/diva_JGR_final.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/January2010/diva_JGR_final.tex:%\\addtocounter{subfigure}{4}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/January2010/diva_JGR_final.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/January2010/diva_JGR_final.tex:%\\addtocounter{subfigure}{6}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/January2010/diva_JGR_final.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/January2010/diva_JGR_final.tex:%\\addtocounter{subfigure}{8}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final.tex:%\\addtocounter{subfigure}{2}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final.tex:%\\addtocounter{subfigure}{2}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final.tex:%\\addtocounter{subfigure}{2}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final.tex:%\\addtocounter{subfigure}{2}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final.tex:The difference between the two fields (with and without outliers) is mapped in Fig. \\ref{fig:salinityoutliers}, along with the suspect data locations. The first striking fact is that most of the suspect data are located near Newfoundland and Labrador shelves. As outlined in Sec.  \\ref{sec:datasources}, this zone is characterized by a strong variability, due to the encounter of Gulf Stream and Labrador Current. Nevertheless, the removal of numerous data in this region did not strongly affect the analyzed field. This is simply explained by the large number of measurements available (see Fig. \\ref{fig:datadensity}).\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final.tex:\\addtocounter{figure}{-1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final.tex:\\addtocounter{subfigure}{2}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final.tex:\\addtocounter{subfigure}{4}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final.tex:\\addtocounter{subfigure}{6}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final.tex:\\addtocounter{subfigure}{8}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final_copy.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final_copy.tex:%\\addtocounter{subfigure}{2}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final_copy.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final_copy.tex:%\\addtocounter{subfigure}{2}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final_copy.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final_copy.tex:%\\addtocounter{subfigure}{2}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final_copy.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final_copy.tex:%\\addtocounter{subfigure}{2}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final_copy.tex:The difference between the two fields (with and without outliers) is mapped in Fig.\\ref{fig:salinityoutliers}, along with the suspect data locations. The first striking fact is that most of the suspect data are located near Newfoundland and Labrador shelves. As outlined in Sec. \\ref{sec:datasources}, this zone is characterized by a strong variability, due to the encounter of Gulf Stream and Labrador Current. Nevertheless, the removal of numerous data in this region did not strongly affect the analyzed field. This is simply explained by the large number of measurements available (see Fig.\\ref{fig:datadensity}).\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final_copy.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final_copy.tex:\\addtocounter{subfigure}{2}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final_copy.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final_copy.tex:\\addtocounter{subfigure}{4}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final_copy.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final_copy.tex:\\addtocounter{subfigure}{6}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final_copy.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Diva_JGR_2009/JGR_October2009/diva_JGR_final_copy.tex:\\addtocounter{subfigure}{8}\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap2_divaclim.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap2_divaclim.tex:\\addtocounter{subfigure}{2}\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap2_divaclim.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap2_divaclim.tex:\\addtocounter{subfigure}{4}\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap2_divaclim.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap2_divaclim.tex:\\addtocounter{subfigure}{6}\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap2_divaclim.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap2_divaclim.tex:\\addtocounter{subfigure}{8}\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap2_divaclim.tex:The difference between the two fields (with and without outliers) is mapped in Fig.~\\ref{fig:salinityoutliers}, along with the suspect data locations. The first striking fact is that most of the suspect data are located near Newfoundland and Labrador shelves. As outlined in Section~\\ref{sec:datasources}, this zone is characterized by a strong variability, due to the encounter of Gulf Stream and Labrador Current. Nevertheless, the removal of numerous data in this region did not strongly affect the analyzed field. This is simply explained by the large number of measurements available (see Fig.~\\ref{fig:datadensity}).\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/PhDconclusions.tex:\\item During upwelling, it is frequent to encounter stratus clouds. These clouds may reduce the quantity of heat that reach the sea surface. The heat fields employed in our simulations were not fine enough to resolve this phenomenon. \n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/vorticy_definitions.tex:For a baroclinic jet, the relevant variable is the potential vorticity. Let us assume the simple case where the balance is only between orbital vorticity and vertical stretching. By definition, the orbital vorticity is higher (lower) in anticylonic (cyclonic) meander, hence the water column has to undergo a vertical stretching (squeezing) to conserve the potential vorticity. Reciprocally, if the jet encounters a variation of topography, it will  generate a modification of the orbital vorticity, thus a veering of the flow. This situation is comparable to what happens when the coastal jet encounters the CGP (Fig.~\\ref{fig:CapeGhirRegion}): the water column is vertically squeezed and then balances this variation of vorticity by a westward turning. However, the reality is more complex: the shear and planetary components of the vorticity also have to come into the picture.\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap5_anomalies.tex:In the subtropical northeast Atlantic Ocean, the seasonal cycle of physical properties is mainly driven by air-sea interactions, namely wind stress and net heat flux. In winter the net heat flux reaches negative values (i.e., transfer from ocean to atmosphere), responsible for the deepening of the thermocline. A late winter phytoplankton bloom is associated to this physical process \\citep[][and references therein]{YODER93}. In summer, trade winds intensify due to the northward motion of the Azores high \\citep{WOOSTER76}, while the net heat flux reaches its maximum. The result of these two counteracting processes is a strong stratification of the ocean surface layers. A shallow mixed layer prevents the injection of nutrients from deeper waters (see for example Fig.~\\ref{fig:T_roms1D}). \n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap5_anomalies.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/TroupinPhD.tex:\\setcounter{tocdepth}{1}\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/TroupinPhD_V2.tex:\\setcounter{tocdepth}{1}\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap4_caibex.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap4_caibex.tex:\\addtocounter{subfigure}{2}\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap4_caibex.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap4_caibex.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap4_caibex.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap4_caibex.tex:Close to the surface, oxygen has concentrations around 4.8~ml/l (Fig.~\\ref{fig:meanprofiles3}b). This concentration decreases and reaches its minimum between 700 and 800~m. At greater depths, the values encountered are similar to those of the surface.  \n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap4_caibex.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap4_caibex.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap4_caibex.tex:\\item[Tracks~9:] between 0 and 50~m, the velocities are predominantly directed westward, with an increased intensity north of 30$^{\\circ}$20'N (Fig.~\\ref{fig:adcp_150khz_nofilter_tracks9_0_100m}a). The vectors in the 300-350~m layer exhibit a counter-flow  south of 30$^{\\circ}$20'N (Fig.~\\ref{fig:adcp_150khz_nofilter_tracks9_0_100m}b).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap4_caibex.tex:\\newblock Fronts, jets, and counter-flows in the {W}estern {I}berian upwelling\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap1_upwelling.tex:%For a baroclinic jet, the relevant variable is the potential vorticity. Let us assume the simple case where the balance is only between orbital vorticity and vertical stretching. By definition, the orbital vorticity is higher (lower) in anticylonic (cyclonic) meander, hence the water column has to undergo a vertical stretching (squeezing) to conserve the potential vorticity. Reciprocally, if the jet encounters a variation of topography, it will  generate a modification of the orbital vorticity, thus a veering of the flow. This situation is comparable to what happens when the coastal jet encounters the CGP (Fig.~\\ref{fig:CapeGhirRegion}): the water column is vertically squeezed and then balances this variation of vorticity by a westward turning. However, the reality is more complex: the shear and planetary components of the vorticity also have to come into the picture.\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap1_upwelling.tex:\\setcounter{enumi}{2}\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap1_upwelling.tex:The main current of our region of study is the Canary Current, which lies between the Strait of Gibraltar and Cape Blanc. It is the extension of the Azores Current, which travels eastward between 32 and 35$^{\\circ}$N \\citep{KLEIN89}. The Azores Current is the southern branch of the Gulf Stream and constitutes the northern part of the North Atlantic subtropical gyre. The Canary Current turns westward just north of the Cape Verde frontal zone, where it becomes the North Equatorial Current \\citep{STRAMMA99}. The latter constitutes the southern limb of the North Atlantic subtropical gyre. The Canary Current is present between the surface and 700-800~m depth. Its transport is estimated at 3~Sv \\citep{STRAMMA84}. \\citet{MASON11} related the seasonal variability of the current to counter-rotating structures generated close to Africa. An undercurrent circulates along the slope at depths near 300~m, coming from a region south of Cape Blanc \\citep{GABRIC93,MACHIN06b}. %An undercurrent was also detected by \\citet{} at a depth of 200~m near to Cape Blanc. %\\citet{PELEGRI05b} detected a subsurface anticyclonic eddy south of Cape Ghir, that they attributed to the interactions between the undercurrent and the local topography. \n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap1_upwelling.tex:\\newblock Fronts, jets, and counter-flows in the {W}estern {I}berian upwelling\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap3_roms.tex:\\item The coastline curvature: the coastline can counteract the stabilization of a western BC due to the $\\beta$~effect or the vortex stretching and then provoke the separation, when the radius of curvature is less than a threshold value $r_{\\min}$. This threshold is estimated as\n",
      "/home/ctroupin/Publis/Published/CharlesThesis/trunk/chap3_roms.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Filament_OM_2011/proof/669_troupin_references_doi2.tex:\\newblock \\bibinfo{title}{Fronts, jets, and counter-flows in the {W}estern\n",
      "/home/ctroupin/Publis/Published/Filament_OM_2011/proof/troupin_references_doi.tex:\\newblock \\bibinfo{title}{Fronts, jets, and counter-flows in the {W}estern\n",
      "/home/ctroupin/Publis/Published/Filament_OM_2011/review1_May2011/Troupin2011Filament0M_revised.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Filament_OM_2011/review1_May2011/Troupin2011Filament0M_revised.tex:\\newblock \\bibinfo{title}{Fronts, jets, and counter-flows in the {W}estern\n",
      "/home/ctroupin/Publis/Published/Filament_OM_2011/review1_May2011/Troupin2011Filament0M_revised.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Filament_OM_2011/review1_May2011/Troupin2011Filament0M_revised2.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Filament_OM_2011/review1_May2011/Troupin2011Filament0M_revised2.tex:\\newblock \\bibinfo{title}{Fronts, jets, and counter-flows in the {W}estern\n",
      "/home/ctroupin/Publis/Published/Filament_OM_2011/review1_May2011/Troupin2011Filament0M_revised2.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Filament_OM_2011/review1_May2011/figures_caption.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Filament_OM_2011/review1_May2011/Troupin2011Filament0M_revised3.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Filament_OM_2011/review1_May2011/Troupin2011Filament0M_revised3.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Filament_OM_2011/TexFiles/V5/Troupin2011Filament0M.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Filament_OM_2011/TexFiles/V1/filamentJPOmechanism.tex:\\item the coastline curvature: the coastline can counteract the stabilization of a western BC due to the $\\beta$~effect or the vortex stretching and then provoke the separation, when the radius of curvature is less than a threshold value $r_{\\min}$. This threshold is estimated as\n",
      "/home/ctroupin/Publis/Published/Filament_OM_2011/TexFiles/V6/Troupin2011Filament0M.tex:%\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Filament_OM_2011/TexFiles/V6/Troupin2011Filament0M.tex:\\addtocounter{figure}{-1}\n",
      "/home/ctroupin/Publis/Published/Filament_OM_2011/TexFiles/V2/filamentJPOmechanism.tex:\\item the coastline curvature: the coastline can counteract the stabilization of a western BC due to the $\\beta$~effect or the vortex stretching and then provoke the separation, when the radius of curvature is less than a threshold value $r_{\\min}$. This threshold is estimated as\n",
      "/home/ctroupin/Publis/Published/Filament_OM_2011/TexFiles/V2/4pablo/filamentJPOmechanism.tex:\\item the coastline curvature: the coastline can counteract the stabilization of a western BC due to the $\\beta$~effect or the vortex stretching and then provoke the separation, when the radius of curvature is less than a threshold value $r_{\\min}$. This threshold is estimated as\n",
      "/home/ctroupin/Publis/Published/Filament_OM_2011/TexFiles/oldfiles/potentialvorticity.tex:For a baroclinic jet, the relevant variable is the potential vorticity. Let us assume the simple case where the balance is only between orbital vorticity and vertical stretching. By definition, the orbital vorticity is higher (lower) in anticylonic (cyclonic) meander, hence the water column has to undergo a vertical stretching (squeezing) to conserve the potential vorticity. Reciprocally, if the jet encounters a variation of topography, it will  generate a modification of the orbital vorticity, thus a veering of the flow. This situation is comparable to what happens when the coastal jet encounters the CGP (Fig.~\\ref{fig:CapeGhirRegion}): the water column is vertically squeezed and then balances this variation of vorticity by a westward turning. However, the reality is more complex: the shear and planetary components of the vorticity also have to come into the picture.\n",
      "/home/ctroupin/Publis/Published/Roms1D_JMS_2008/enkf_fl.tex:\\setcounter{equation}{3}\n",
      "/home/ctroupin/Publis/Published/Roms1D_JMS_2008/enkf_fl.tex:Applying Kalman filters to biogeochemical models must be done carefully: on one hand, the state vector has to be physically consistent to be further propagated by the model (\\textit{e.g.} negative concentrations are totally unrealistic) and on the other hand, state and observation vectors have to be multivariate normally distributed variables for optimal use of the linear statistical analysis. The latter requirement is rarely encountered when the model used is nonlinear. One solution is the Gaussian anamorphosis.\n",
      "/home/ctroupin/Publis/Published/Roms1D_JMS_2008/sampleAGU.tex:%  EQUATION NUMBERING: COUNTER\n",
      "/home/ctroupin/Publis/Published/Roms1D_JMS_2008/sampleAGU.tex:% the equation counter or by explicitly numbering\n",
      "/home/ctroupin/Publis/Published/Roms1D_JMS_2008/sampleAGU.tex:% according to the equation counter.\n",
      "/home/ctroupin/Publis/Published/Roms1D_JMS_2008/sampleAGU.tex:% To reset the equation counter, place the setcounter{equation}\n",
      "/home/ctroupin/Publis/Published/Roms1D_JMS_2008/sampleAGU.tex:%\\setcounter{equation}{0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ctroupin/Publis/Published/Roms1D_JMS_2008/sampleAGU.tex:% Set the equation counter to 0 if the next\n",
      "/home/ctroupin/Publis/Published/Roms1D_JMS_2008/sampleAGU.tex:% The \\setcounter{equation} command does affect\n",
      "/home/ctroupin/Publis/Published/Roms1D_JMS_2008/sampleAGU.tex:%  FIGURE, PLATE, AND TABLE NUMBERING: COUNTERS\n",
      "/home/ctroupin/Publis/Published/Roms1D_JMS_2008/sampleAGU.tex:% To set counters explicitly:\n",
      "/home/ctroupin/Publis/Published/Roms1D_JMS_2008/RevisionFinal/Troupin2010JMSpostprint.tex:Results are very similar from June to December, with a maximal difference being close to 20 m. In winter and spring, differences larger than 50 m are encountered. Possible explanations are the lack of resolution of the model at these depths and the mathematical definition of MLD.\n",
      "/home/ctroupin/Publis/Published/Roms1D_JMS_2008/RevisionFinal/Troupin2010JMSpostprint.tex:\\cite{ARISTEGUI01} reported a small chlorophyll bloom, with values larger than the annual mean, but lower than those encountered in temperate regions.\n",
      "/home/ctroupin/Publis/Published/Roms1D_JMS_2008/RevisionFinal/Troupin_revised2_eehedits_30aug.tex:Results are very similar from June to December, with a maximal difference being close to 20 m. In winter and spring, differences larger than 50 m are encountered. Possible explanations are the lack of resolution of the model at these depths and the mathematical definition of MLD.\n",
      "/home/ctroupin/Publis/Published/Roms1D_JMS_2008/RevisionFinal/Troupin_revised2_eehedits_30aug.tex:\\cite{ARISTEGUI01} reported a small chlorophyll bloom, with values larger than the annual mean, but lower than those encountered in temperate regions.\n",
      "/home/ctroupin/Publis/Published/Roms1D_JMS_2008/instructions-harv.tex:  counter as the \\texttt{thm} environment.\n",
      "/home/ctroupin/ULg/gher-ulg.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% This is the counter used by @enumerate, which is really @itemize\n",
      "/home/ctroupin/ULg/gher-ulg.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% we encounter the problem it was intended to solve again.\n",
      "/home/ctroupin/ULg/gher-ulg.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:      \\global\\colcount=0 % Reset the column counter.\n",
      "/home/ctroupin/ULg/gher-ulg.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% This counter is funny since it counts through charcodes of letters A, B, ...\n",
      "/home/ctroupin/ULg/gher-ulg.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% @chapter, @appendix, @unnumbered.  Increment top-level counter, reset\n",
      "/home/ctroupin/ULg/gher-ulg.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% all lower-level sectioning counters to zero.\n",
      "/home/ctroupin/ULg/gher-ulg.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% If we encounter &foo, then turn on ()-hacking afterwards\n",
      "/home/ctroupin/ULg/gher-ulg.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% We keep a separate counter for each FLOATTYPE, which we reset at each\n",
      "/home/ctroupin/ULg/gher-ulg.github.io/vendor/bundle/ruby/2.3.0/gems/ffi-1.9.18/ext/ffi_c/libffi/texinfo.tex:% The parameter is the control sequence identifying the counter we are\n",
      "/home/ctroupin/ULg/Diva-User-Guide/src/old/DivaUserGuide2013.tex:\\setcounter{tocdepth}{1}\n",
      "/home/ctroupin/ULg/Diva-User-Guide/src/old/DivaUserGuide2012.tex:\\setcounter{tocdepth}{1}\n",
      "/home/ctroupin/ULg/Diva-User-Guide/src/Emodnetspecials.tex:\\setcounter{tocdepth}{1}\n",
      "/home/ctroupin/ULg/Diva-User-Guide/src/16-DivaProblems.tex:\\diva uses a memory allocation for the largest problem encountered. This \n",
      "/home/ctroupin/ULg/Diva-User-Guide/src/16-DivaProblems.tex:The following problems should not appear any more in the latest version of \\diva. Should you encounter them, please contact us.\n",
      "/home/ctroupin/ULg/Diva-User-Guide/src/DivaUserGuide.tex:\\setcounter{tocdepth}{1}\n",
      "/home/ctroupin/ULg/DivaUserGuideSVN/tags/DivaUserGuide_March2013/DivaUserGuide_March2013.tex:\\setcounter{tocdepth}{1}\n",
      "/home/ctroupin/ULg/DivaUserGuideSVN/tags/DivaUserGuide_March2013/16-DivaProblems.tex:\\diva uses a memory allocation for the largest problem encountered. This \n",
      "/home/ctroupin/ULg/DivaUserGuideSVN/tags/DivaUserGuide_March2013/16-DivaProblems.tex:The following problems should not appear any more in the latest version of \\diva. Should you encounter them, please let use know.\n",
      "/home/ctroupin/ULg/DivaUserGuideSVN/DivaUserGuide2013.tex:\\setcounter{tocdepth}{1}\n",
      "/home/ctroupin/ULg/DivaUserGuideSVN/Emodnetspecials.tex:\\setcounter{tocdepth}{1}\n",
      "/home/ctroupin/ULg/DivaUserGuideSVN/DivaUserGuide2012.tex:\\setcounter{tocdepth}{1}\n",
      "/home/ctroupin/ULg/DivaUserGuideSVN/16-DivaProblems.tex:\\diva uses a memory allocation for the largest problem encountered. This \n",
      "/home/ctroupin/ULg/DivaUserGuideSVN/16-DivaProblems.tex:The following problems should not appear any more in the latest version of \\diva. Should you encounter them, please contact us.\n",
      "/home/ctroupin/ULg/DivaUserGuideSVN/DivaUserGuide.tex:\\setcounter{tocdepth}{1}\n",
      "/home/ctroupin/ULg/MODB_backup/BibTexFiles/PubliUpwelling.tex:%\\newblock {M}ean structure of the inshore countercurrent and {C}alifornia\n",
      "/home/ctroupin/ULg/MODB_backup/BibTexFiles/PubliUpwelling.tex:%\\newblock Fronts, jets, and counter-flows in the {W}estern {I}berian upwelling\n",
      "/home/ctroupin/ULg/MODB_backup/BibTexFiles/PubliUpwelling.tex:%\\newblock A separated jet and coastal counterflow during upwelling relaxation\n",
      "grep: /home/ctroupin/Presentations/2017/20171016_SeaDataCloud_Athens/SeaDataCloud_GHER_plenary_.tex: No such file or directory\n",
      "grep: /home/ctroupin/Presentations/2017/20171116_OpenSeaLab_Anvers/LaTex/OpenSeaLab_Gridded.tex: No such file or directory\n",
      "/home/ctroupin/Presentations/PresentationsLatex/20180528_Colloquium_Liege/CLQ2018_Poster.tex:\\setcounter{\\item}{8}\n",
      "/home/ctroupin/Downloads/academicons/academicons.tex:\\newtotcounter{IconsCounter}\n",
      "/home/ctroupin/Downloads/academicons/academicons.tex:\\setcounter{IconsCounter}{0}\n",
      "/home/ctroupin/Downloads/academicons/academicons.tex:The \\textsf{\\jobname} package provides specific \\hologo{(La)TeX} bindings with the free \\emph{Academicons} font, allowing to access \\total{IconsCounter} high quality icons of online academic profiles.\n",
      "/home/ctroupin/Downloads/academicons/academicons.tex:The \\textsf{\\jobname} package provides access in \\hologo{(La)TeX} to \\total{IconsCounter} high quality icons of online academic profiles included in the free \\emph{Academicons} font. This package requires the \\textsf{fontspec} package and either the \\hologo{Xe}\\hologo{(La)TeX} or Lua\\hologo{(La)TeX} engine to load the \\emph{Academicons} font from the system, which requires installing the bundled \\texttt{academicons.ttf} font file. As new releases come out, it is recommended to install the bundled font version as there may be differences between the package and previous font versions or newest font versions not yet contemplated in the package.\n",
      "/home/ctroupin/Downloads/academicons/academicons.tex:\\stepcounter{IconsCounter}%\n",
      "/home/ctroupin/Downloads/academicons/academicons.tex:\\stepcounter{IconsCounter}%\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "find /home/ctroupin/ -name '*.tex' -exec grep -i 'counter'  {} +"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find most recent file by extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "find . -name '*' -printf \"%T+\\t%p\\n\" | sort -r | head -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Files not containing given string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grep -L \"foo\" *html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## ODV spreadsheet processing\n",
    "Specific commands to process the Ocean Data View spreadsheets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove lines starting with a \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sed -i '/^\\/\\//d' filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove lines with number of columns lower than ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "awk 'NF>=12' filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print columns, given field separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "awk 'BEGIN { FS=\"\\t\" } { print $5, $6 }' filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicate lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "awk '!a[$0]++' filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF processing\n",
    "Use [pdftk](https://www.pdflabs.com/docs/pdftk-cli-examples/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdftk input.pdf cat 14 output output.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
